---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


Machine Learning Master's student at the University of Warsaw, advised by [Yuhuai Wu](http://www.cs.toronto.edu/~ywu) and [Piotr Miłoś](https://scholar.google.com/citations?user=Se68XecAAAAJ&hl=en)

Large language model enthusiast interested in advancing LLM efficiency and reasoning capabilities. My recent work has been dedicated to training language models to prove mathematical theorems and equipping them with the ability to leverage vast knowledge bases through retrieval. I am thrilled by the current progress in the field and seek new challenges to further explore the potential of LLMs.

Publication
------
[**Thor: Wielding Hammers to Integrate Language Models and Automated Theorem Provers**](https://arxiv.org/abs/2205.10893)
Albert Q. Jiang, Wenda Li, **Szymon Tworkowski**, Konrad Czechowski, Tomasz Odrzygóźdź, Piotr Miłoś, Yuhuai Wu, Mateja Jamnik

[NeurIPS 2022](https://openreview.net/forum?id=fUeOyt-2EOp)

[**Hierarchical Transformers Are More Efficient Language Models**](https://arxiv.org/abs/2110.13711)
Piotr Nawrot*, **Szymon Tworkowski***, Michał Tyrolski, Łukasz Kaiser, Yuhuai Wu, Christian Szegedy, Henryk Michalewski

[NAACL 2022, Findings](https://aclanthology.org/2022.findings-naacl.117.pdf)

[**Formal Premise Selection With Language Models**](http://aitp-conference.org/2022/abstract/AITP_2022_paper_32.pdf)
**Szymon Tworkowski***, Maciej Mikuła*, Tomasz Odrzygóźdź*, Konrad Czechowski*, Szymon Antoniak*, Albert Q. Jiang, Christian Szegedy, Łukasz Kuciński, Piotr Miłoś, Yuhuai Wu

[AITP 2022](http://aitp-conference.org/2022/abstract/AITP_2022_paper_32.pdf)

[**Magnushammer: A Transformer-based Approach to Premise Selection**](https://arxiv.org/abs/2303.04488)
Maciej Mikuła*, Szymon Antoniak*, **Szymon Tworkowski***, Albert Qiaochu Jiang, Jin Peng Zhou, Christian Szegedy, Łukasz Kuciński, Piotr Miłoś, Yuhuai Wu

[arXiv'23](https://arxiv.org/abs/2303.04488)
